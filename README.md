# ğŸŒ¦ï¸ Full-Stack On-Premise Data Pipeline for IoT & Weather Analytics

## ğŸ“Œ Project Overview

This project simulates a real-time weather analytics platform using open-source tools. It ingests weather data from public APIs and synthetic sources, processes it using Apache Spark, stores it in Hive and MySQL, and orchestrates everything with Apache Airflow. Monitoring is enabled via Grafana and Prometheus. The system is designed for on-premise deployment and optionally containerized using Docker Compose.

---

## ğŸ§± Folder Structure
```
weather_pipeline_project/ â”œâ”€â”€ airflow/ â”‚ â”œâ”€â”€ airflow.cfg â”‚ â”œâ”€â”€ airflow.db â”‚ â”œâ”€â”€ dags/ â”‚ â”‚ â”œâ”€â”€ weather_to_kafka_dag.py â”‚ â”‚ â”œâ”€â”€ faker_ingestion_dag.py â”‚ â”‚ â”œâ”€â”€ batch_etl_dag.py â”‚ â”‚ â””â”€â”€ connectivity_check_dag.py â”œâ”€â”€ kafka/ â”‚ â””â”€â”€ weather_to_kafka.py â”œâ”€â”€ faker/ â”‚ â””â”€â”€ faker_ingestion.py â”œâ”€â”€ spark/ â”‚ â”œâ”€â”€ spark_streaming.py â”‚ â”œâ”€â”€ spark_batch_etl.py â”‚ â””â”€â”€ last_etl_timestamp.txt â”œâ”€â”€ hive/ â”‚ â”œâ”€â”€ create_final_table.sql â”‚ â””â”€â”€ apache-hive-3.1.3-bin/ â”œâ”€â”€ hadoop/ â”‚ â””â”€â”€ hadoop-3.3.6/ â”œâ”€â”€ csv_parquet_storage/ â”‚ â”œâ”€â”€ csv_output/ â”‚ â”œâ”€â”€ parquet_output/ â”‚ â”œâ”€â”€ hive_final_table_export/ â”‚ â””â”€â”€ checkpoint/ â”œâ”€â”€ spark-events/ â”‚ â””â”€â”€ [Spark application logs] â”œâ”€â”€ kafka-logs/ â”‚ â””â”€â”€ [Kafka broker logs] â”œâ”€â”€ grafana/ â”‚ â””â”€â”€ [Grafana setup files] â”œâ”€â”€ zookeeper-data/ â”‚ â””â”€â”€ [Zookeeper metadata]
```
